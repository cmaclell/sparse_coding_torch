{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ddd5bf-7615-45a2-bd9c-9827e7c2b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from conv_sparse_model import ConvSparseLayer\n",
    "\n",
    "from train_conv3d_sparse_model import load_balls_data\n",
    "from train_conv3d_sparse_model import plot_original_vs_recon\n",
    "from train_conv3d_sparse_model import plot_filters\n",
    "from train_conv3d_sparse_model import plot_video\n",
    "\n",
    "from video_loader import VideoLoader\n",
    "from video_loader import MinMaxScaler\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77fb5ce9-f213-4196-bebf-79dabd00de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_balls_data(batch_size):\n",
    "    \n",
    "    with open('ball_videos.npy', 'rb') as fin:\n",
    "        ball_videos = torch.tensor(np.load(fin)).float()\n",
    "\n",
    "    batch_size = batch_size\n",
    "    train_loader = torch.utils.data.DataLoader(ball_videos,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888a5e5f-96ac-4f5f-b540-f3acc888cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bamc_data(batch_size):\n",
    "    video_path = \"/home/cm3786@drexel.edu/bamc_data/\"\n",
    "    transforms = torchvision.transforms.Compose([torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "                                                 torchvision.transforms.Resize(size=(160, 90)), \n",
    "                                                 MinMaxScaler(0, 255)])\n",
    "    dataset = VideoLoader(video_path, transform=transforms, num_frames=60)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86142a5-930b-4a0c-ab7a-6be63a1d1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cpu\":\n",
    "    batch_size = 1\n",
    "else:\n",
    "    batch_size = 4*3\n",
    "\n",
    "# train_loader = load_balls_data(batch_size)\n",
    "train_loader = load_bamc_data(batch_size)\n",
    "\n",
    "example_data = next(iter(train_loader))\n",
    "\n",
    "sparse_layer = ConvSparseLayer(in_channels=1,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=5,\n",
    "                               stride=1,\n",
    "                               padding=0,\n",
    "                               convo_dim=3,\n",
    "                               rectifier=True,\n",
    "                               shrink=0.25,\n",
    "                               lam=0.5,\n",
    "                               max_activation_iter=200,\n",
    "                               activation_lr=1e-2)\n",
    "model = torch.nn.DataParallel(sparse_layer, device_ids=[1, 2, 3])\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "filter_optimizer = torch.optim.Adam(sparse_layer.parameters(),\n",
    "                                    lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca61d5d-4f75-4409-b860-5d453b17e856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 60, 90, 160])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e0995-4aa5-418f-acb6-d10c5b4f4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = plot_video(example_data[1][0])\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607af8e-7dd1-4bb9-9578-95c279465f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activations took 27.950331718020607 sec\n",
      "epoch=0, loss=1549.7274169921875\n",
      "\n",
      "activations took 23.936351343989372 sec\n",
      "epoch=0, loss=1460.863525390625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    # for local_batch in train_loader:\n",
    "    for labels, local_batch in train_loader:\n",
    "        local_batch = local_batch.to(device)\n",
    "        t1 = time.perf_counter()\n",
    "        activations = model(local_batch)\n",
    "        t2 = time.perf_counter()\n",
    "        print('activations took {} sec'.format(t2-t1))\n",
    "        loss = sparse_layer.loss(local_batch, activations)\n",
    "        print('epoch={}, loss={}'.format(epoch, loss))\n",
    "        print()\n",
    "\n",
    "        filter_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        filter_optimizer.step()\n",
    "        sparse_layer.normalize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7392d33-29af-4543-95a8-2a255d234dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = sparse_layer(example_data[1][:1].to(device))\n",
    "reconstructions = sparse_layer.reconstructions(\n",
    "    activations).cpu().detach().numpy()\n",
    "\n",
    "ani = plot_original_vs_recon(example_data[1], reconstructions, idx=0)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90faceb0-6ede-4325-837c-7b53743a0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = plot_filters(sparse_layer.filters.cpu().detach())\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cf8c8-db9e-4c14-b9f0-418e1893ea05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chris-py3.9.6",
   "language": "python",
   "name": "chris-py3.9.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
