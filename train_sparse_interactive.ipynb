{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b9c221-6cb2-4708-8654-02d0721e19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sparse_model import SparseLayer\n",
    "\n",
    "from train_sparse_model import load_mnist_data\n",
    "from train_sparse_model import plot_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5539999-0694-4928-84f4-8550fffb69fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cm3786@drexel.edu/.pyenv/versions/3.9.6/envs/jupyter3.9.6/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cpu\":\n",
    "    batch_size = 64\n",
    "else:\n",
    "    batch_size = 4096\n",
    "\n",
    "train_loader = load_mnist_data(batch_size)\n",
    "example_data, example_targets = next(iter(train_loader))\n",
    "\n",
    "idx = 0\n",
    "num_img = 32\n",
    "num_filters = 784\n",
    "imgs = example_data[idx:idx+num_img, 0, :, :].to(device)\n",
    "sparse_layer = SparseLayer(imgs.shape[1], imgs.shape[2], num_filters)\n",
    "sparse_layer.to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "filter_optimizer = torch.optim.Adam(sparse_layer.parameters(),\n",
    "                                    lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ec7e7d-222d-482b-8fae-31aeeaf57c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=339.3970031738281\n",
      "loss=302.4366455078125\n",
      "loss=265.2920837402344\n",
      "loss=246.69708251953125\n",
      "loss=232.9738311767578\n",
      "loss=222.8897705078125\n",
      "loss=215.71499633789062\n",
      "loss=207.3680877685547\n",
      "loss=201.38571166992188\n",
      "loss=195.90518188476562\n",
      "loss=190.6444549560547\n",
      "loss=185.08001708984375\n",
      "loss=182.55438232421875\n",
      "loss=178.92910766601562\n",
      "loss=175.71067810058594\n"
     ]
    }
   ],
   "source": [
    "# for _ in range(20):\n",
    "#     activations = sparse_layer(imgs)\n",
    "#     loss = sparse_layer.loss(imgs, activations)\n",
    "for epoch in range(1):\n",
    "    for local_batch, local_labels in train_loader:\n",
    "        local_batch = local_batch.to(device)\n",
    "        local_labels = local_labels.to(device)\n",
    "        activations = sparse_layer(local_batch[:, 0, :, :])\n",
    "        loss = sparse_layer.loss(local_batch[:, 0, :, :], activations)\n",
    "        print('loss={}'.format(loss))\n",
    "\n",
    "        filter_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        filter_optimizer.step()\n",
    "        sparse_layer.normalize_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e55d6-d15e-484f-af18-93587495cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = sparse_layer(imgs)\n",
    "reconstructions = sparse_layer.reconstructions(\n",
    "    activations).cpu().detach().numpy()\n",
    "\n",
    "print(\"SHAPES\")\n",
    "print(imgs.shape)\n",
    "print(reconstructions.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "img_to_show = 3\n",
    "for i in range(img_to_show):\n",
    "    # original\n",
    "    plt.subplot(img_to_show, 2, i*2 + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[idx+i, 0, :, :], cmap='gray',\n",
    "               interpolation='none')\n",
    "    plt.title(\"Original Image\\nGround Truth: {}\".format(\n",
    "        example_targets[idx]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # reconstruction\n",
    "    plt.subplot(img_to_show, 2, i*2 + 2)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(reconstructions[i, :, :], cmap='gray',\n",
    "               interpolation='none')\n",
    "    plt.title(\"Reconstruction\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chris-py3.9.6",
   "language": "python",
   "name": "chris-py3.9.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
